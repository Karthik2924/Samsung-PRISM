{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of audio classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk6bZ9uMRYMb",
        "outputId": "ea4b8479-38df-4426-df42-dd5d7fd8e176",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install soundfile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y_Y0jJxFwxz"
      },
      "source": [
        "import numpy as np\n",
        "import os \n",
        "import sys\n",
        "import glob\n",
        "import librosa\n",
        "#import soundfile\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYcS89jYNN1d"
      },
      "source": [
        "categories=['spoof','bonafide']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQeJEVLMJGdd"
      },
      "source": [
        "def extract_features(parent_dir,sub_dirs,file_ext=\"*.flac\",\n",
        "                     bands=60,frames=41):\n",
        "    def _windows(data, window_size):\n",
        "        start = 0\n",
        "        while start < len(data):\n",
        "            yield int(start), int(start + window_size)\n",
        "            start += (window_size // 2)\n",
        "\n",
        "    window_size = 512 * (frames - 1)\n",
        "    features, labels = [], []\n",
        "    for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
        "        segment_log_specgrams, segment_labels = [], []\n",
        "        sound_clip,sr = librosa.load(fn)\n",
        "        categories=['spoof','bonafide']\n",
        "        label = categories.index(sub_dirs)\n",
        "        #label = int(fn.split('/')[2].split('-')[1])\n",
        "        for (start,end) in _windows(sound_clip,window_size):\n",
        "            if(len(sound_clip[start:end]) == window_size):\n",
        "                signal = sound_clip[start:end]\n",
        "                melspec = librosa.feature.melspectrogram(signal,n_mels=bands)\n",
        "                logspec = librosa.amplitude_to_db(melspec)\n",
        "                logspec = logspec.T.flatten()[:, np.newaxis].T\n",
        "                segment_log_specgrams.append(logspec)\n",
        "                segment_labels.append(label)\n",
        "\n",
        "        segment_log_specgrams = np.asarray(segment_log_specgrams).reshape(\n",
        "            len(segment_log_specgrams),bands,frames,1)\n",
        "        segment_features = np.concatenate((segment_log_specgrams, np.zeros(\n",
        "            np.shape(segment_log_specgrams))), axis=3)\n",
        "        for i in range(len(segment_features)):\n",
        "            segment_features[i, :, :, 1] = librosa.feature.delta(\n",
        "                segment_features[i, :, :, 0])\n",
        "\n",
        "        if len(segment_features) > 0: # check for empty segments\n",
        "            features.append(segment_features)\n",
        "            labels.append(segment_labels)\n",
        "    return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A4D_I4pMI85"
      },
      "source": [
        "parent_dir = '/content/drive/My Drive/dataset/Samsung_PRISM/'\n",
        "save_dir = \"/content/drive/My Drive/dataset/Samsung_PRISM/data/\"\n",
        "folds = sub_dirs = np.array(['bonafide','spoof'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfHuoNe2Rfhw"
      },
      "source": [
        "for sub_dir in sub_dirs:\n",
        "    features, labels = extract_features(parent_dir,sub_dir)\n",
        "    np.savez(\"{0}{1}\".format(save_dir, sub_dir),\n",
        "             features=features,\n",
        "             labels=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX8cDY1QSS7G"
      },
      "source": [
        "features[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGS_2JpESTsf",
        "outputId": "f405c376-7a3e-425c-b461-6d686b3ba172",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.shape(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(199,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND9tvhf9ScSi"
      },
      "source": [
        "def get_network():\n",
        "    num_filters = [24,32,64,128]\n",
        "    pool_size = (2, 2)\n",
        "    kernel_size = (3, 3)\n",
        "    input_shape = (60, 41, 2)\n",
        "    num_classes = 2\n",
        "    keras.backend.clear_session()\n",
        "\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(24, kernel_size,\n",
        "                padding=\"same\", input_shape=input_shape))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation(\"relu\"))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(32, kernel_size,\n",
        "                                  padding=\"same\"))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation(\"relu\"))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(64, kernel_size,\n",
        "                                  padding=\"same\"))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation(\"relu\"))\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
        "\n",
        "    model.add(keras.layers.Conv2D(128, kernel_size,\n",
        "                                  padding=\"same\"))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Activation(\"relu\"))\n",
        "\n",
        "    model.add(keras.layers.GlobalMaxPooling2D())\n",
        "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(num_classes, activation=\"sigmoid\"))\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFVpN3OkHJrb",
        "outputId": "163f6120-f55d-4ed7-feb7-f7b07fbb5eee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracies = []\n",
        "folds = np.array(['bonafide','spoof'])\n",
        "load_dir = '/content/data/'\n",
        "kf = KFold(n_splits=2)\n",
        "for train_index, test_index in kf.split(folds):\n",
        "    x_train, y_train = [], []\n",
        "    for ind in train_index:\n",
        "        # read features or segments of an audio file\n",
        "        train_data = np.load(\"{0}/{1}.npz\".format(load_dir,folds[ind]),\n",
        "                       allow_pickle=True)\n",
        "        # for training stack all the segments so that they are treated as an example/instance\n",
        "        features = np.concatenate(train_data[\"features\"], axis=0)\n",
        "        labels = np.concatenate(train_data[\"labels\"], axis=0)\n",
        "        x_train.append(features)\n",
        "        y_train.append(labels)\n",
        "    # stack x,y pairs of all training folds\n",
        "    x_train = np.concatenate(x_train, axis = 0).astype(np.float32)\n",
        "    y_train = np.concatenate(y_train, axis = 0).astype(np.float32)\n",
        "\n",
        "    # for testing we will make predictions on each segment and average them to\n",
        "    # produce signle label for an entire sound clip.\n",
        "    test_data = np.load(\"{0}/{1}.npz\".format(load_dir,\n",
        "                   folds[test_index][0]), allow_pickle=True)\n",
        "    x_test = test_data[\"features\"]\n",
        "    y_test = test_data[\"labels\"]\n",
        "\n",
        "    model = get_network()\n",
        "    model.fit(x_train, y_train, epochs = 50, batch_size = 24, verbose = 0)\n",
        "\n",
        "    # evaluate on test set/fold\n",
        "    y_true, y_pred = [], []\n",
        "    for x, y in zip(x_test, y_test):\n",
        "        # average predictions over segments of a sound clip\n",
        "        avg_p = np.argmax(np.mean(model.predict(x), axis = 0))\n",
        "        y_pred.append(avg_p)\n",
        "        # pick single label via np.unique for a sound clip\n",
        "        y_true.append(np.unique(y)[0])\n",
        "    accuracies.append(accuracy_score(y_true, y_pred))\n",
        "print(\"Average 10 Folds Accuracy: {0}\".format(np.mean(accuracies)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average 10 Folds Accuracy: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqImcYJUWqB1"
      },
      "source": [
        "pdata = np.load('/content/drive/My Drive/dataset/Samsung_PRISM/data/bonafide.npz',allow_pickle=True)\n",
        "ndata = np.load('/content/drive/My Drive/dataset/Samsung_PRISM/data/spoof.npz',allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDtgCGRTW5a5"
      },
      "source": [
        "x=[]\n",
        "y=[]\n",
        "features = np.concatenate(pdata[\"features\"], axis=0)\n",
        "labels = np.concatenate(pdata[\"labels\"], axis=0)\n",
        "x.extend(features)\n",
        "y.extend(labels)\n",
        "features = np.concatenate(ndata[\"features\"], axis=0)\n",
        "labels = np.concatenate(ndata[\"labels\"], axis=0)\n",
        "x.extend(features)\n",
        "y.extend(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x9GsM0QpQQz",
        "outputId": "1a7776f9-13e0-4129-d895-51babc3c24fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.unique(y,return_counts=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([ 942, 1378]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwFyO066p_2T"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1ACAg6QqhKJ",
        "outputId": "b43ef1d5-7bb0-4f97-ae07-af2ddaac29af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kxxttm2-W5dg"
      },
      "source": [
        "model=get_network()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT4LBCaCgkjI",
        "outputId": "ac905801-8934-4644-b048-33fc0d181e1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 60, 41, 24)        456       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 60, 41, 24)        96        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 60, 41, 24)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 30, 20, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 20, 32)        6944      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 30, 20, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 20, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 10, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 15, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 15, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 5, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 7, 5, 128)         512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 7, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d (Global (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 117,514\n",
            "Trainable params: 117,018\n",
            "Non-trainable params: 496\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeBCE7kggkui",
        "outputId": "80e5f11e-2546-4ffc-98db-b2e685aee192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(np.array(X_train),np.array(y_train),epochs=25,batch_size=32,verbose=1,validation_data=(np.array(X_test),np.array(y_test)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "55/55 [==============================] - 8s 150ms/step - loss: 0.4713 - accuracy: 0.7649 - val_loss: 0.8944 - val_accuracy: 0.5897\n",
            "Epoch 2/25\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 0.2890 - accuracy: 0.8776 - val_loss: 0.6157 - val_accuracy: 0.6172\n",
            "Epoch 3/25\n",
            "55/55 [==============================] - 8s 144ms/step - loss: 0.2062 - accuracy: 0.9236 - val_loss: 0.2690 - val_accuracy: 0.9224\n",
            "Epoch 4/25\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 0.1544 - accuracy: 0.9517 - val_loss: 0.2097 - val_accuracy: 0.9259\n",
            "Epoch 5/25\n",
            "55/55 [==============================] - 8s 151ms/step - loss: 0.1206 - accuracy: 0.9661 - val_loss: 0.1756 - val_accuracy: 0.9362\n",
            "Epoch 6/25\n",
            "55/55 [==============================] - 8s 143ms/step - loss: 0.0901 - accuracy: 0.9787 - val_loss: 0.1839 - val_accuracy: 0.9190\n",
            "Epoch 7/25\n",
            "55/55 [==============================] - 8s 143ms/step - loss: 0.0716 - accuracy: 0.9833 - val_loss: 0.2035 - val_accuracy: 0.9086\n",
            "Epoch 8/25\n",
            "55/55 [==============================] - 8s 144ms/step - loss: 0.0620 - accuracy: 0.9885 - val_loss: 0.1424 - val_accuracy: 0.9379\n",
            "Epoch 9/25\n",
            "55/55 [==============================] - 8s 147ms/step - loss: 0.0468 - accuracy: 0.9920 - val_loss: 0.1635 - val_accuracy: 0.9207\n",
            "Epoch 10/25\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 0.0345 - accuracy: 0.9977 - val_loss: 0.1112 - val_accuracy: 0.9586\n",
            "Epoch 11/25\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 0.0339 - accuracy: 0.9943 - val_loss: 0.0796 - val_accuracy: 0.9793\n",
            "Epoch 12/25\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 0.0217 - accuracy: 0.9994 - val_loss: 0.0818 - val_accuracy: 0.9724\n",
            "Epoch 13/25\n",
            "55/55 [==============================] - 8s 147ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9672\n",
            "Epoch 14/25\n",
            "55/55 [==============================] - 8s 148ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.0642 - val_accuracy: 0.9828\n",
            "Epoch 15/25\n",
            "55/55 [==============================] - 8s 148ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9759\n",
            "Epoch 16/25\n",
            "55/55 [==============================] - 8s 150ms/step - loss: 0.0145 - accuracy: 0.9994 - val_loss: 0.0574 - val_accuracy: 0.9828\n",
            "Epoch 17/25\n",
            "55/55 [==============================] - 8s 149ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9707\n",
            "Epoch 18/25\n",
            "55/55 [==============================] - 8s 147ms/step - loss: 0.0088 - accuracy: 0.9994 - val_loss: 0.0567 - val_accuracy: 0.9810\n",
            "Epoch 19/25\n",
            "55/55 [==============================] - 8s 145ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0505 - val_accuracy: 0.9810\n",
            "Epoch 20/25\n",
            "55/55 [==============================] - 8s 146ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9741\n",
            "Epoch 21/25\n",
            "55/55 [==============================] - 8s 150ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0484 - val_accuracy: 0.9879\n",
            "Epoch 22/25\n",
            "55/55 [==============================] - 9s 160ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0479 - val_accuracy: 0.9810\n",
            "Epoch 23/25\n",
            "55/55 [==============================] - 8s 147ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 0.9810\n",
            "Epoch 24/25\n",
            "55/55 [==============================] - 8s 148ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0476 - val_accuracy: 0.9810\n",
            "Epoch 25/25\n",
            "55/55 [==============================] - 8s 147ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fac91b2b780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGhCg6JKIs8L",
        "outputId": "426579dd-9b3a-46e3-c56b-22d06a4395a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model.fit(x, y, epochs = 3, batch_size = 24, verbose = 1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-98463c7af7f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m     self._adapter = adapter_cls(\n\u001b[1;32m   1106\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 971\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    972\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m     raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'numpy.ndarray'>\"}), (<class 'list'> containing values of types {\"<class 'numpy.int64'>\"})"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCLKYZCnK2dh",
        "outputId": "37d9b017-7c8f-45e7-b9b9-55097df09331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.shape(x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1378, 60, 41, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BGyabgYRYto",
        "outputId": "46ebdaa4-f636-494d-ceee-8a56ab7ab684",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.shape(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(199,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fkGjB--RvF5",
        "outputId": "9dedd95f-30f1-42f0-f039-3926359fcc8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXGQd3OnR06V",
        "outputId": "7a16232f-0a59-46a3-af7a-bde2cfb9d2d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "np.unique(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([0]), list([0, 0]), list([0, 0, 0]), list([0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0]), list([0, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0]), list([0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              "       list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWoNj-49U_6G",
        "outputId": "4de55178-2e78-42f8-fb31-b8df922c6acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFlBOc4XVkWR",
        "outputId": "043652e7-a711-4357-bb2f-2379eba00e9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ind"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKptgCXV2cZ",
        "outputId": "20a70cb9-5f6b-4743-da4a-b047280d173a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "kf.split(folds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object _BaseKFold.split at 0x7f238fc29888>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIVA5JCXV7Zs",
        "outputId": "c04cfe06-cbb3-4875-bd84-fc6423b16eba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 1., 1., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXhFIo5hWTG1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}